{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data and scaling it\n",
    "\n",
    "dataRaw = sklearn.datasets.load_wine()\n",
    "\n",
    "X = dataRaw['data']\n",
    "Y = dataRaw['target']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# Getting feature names of the data\n",
    "featureNames = dataRaw['feature_names']\n",
    "print(featureNames)\n",
    "\n",
    "# Shuffling array \n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "\n",
    "\n",
    "# Scaling data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data to training and test set\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining forward selection algorithm \n",
    "\n",
    "def forward_selector(maxFeatureN, train_y, test_y, train_X, test_X, random_seed, cv_k, originalData):\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    returnList = {\"maxFeatureN\": maxFeatureN}\n",
    "    \n",
    "    candFeatures = list(range(train_X.shape[1]))\n",
    "    selection = []\n",
    "    \n",
    "    for i in range(maxFeatureN):\n",
    "        accuracyScores = []\n",
    "        \n",
    "        for c in candFeatures: \n",
    "            S = list(selection)\n",
    "            S.append(c)\n",
    "\n",
    "            train_X_S = train_X[:,S]\n",
    "\n",
    "            # fitting SVM classifier\n",
    "            svm_classifier = sklearn.svm.LinearSVC()\n",
    "\n",
    "            accuraccy = np.mean(model_selection.cross_val_score(svm_classifier, \n",
    "                                                                train_X_S, \n",
    "                                                                train_y, \n",
    "                                                                cv=cv_k, \n",
    "                                                                scoring='accuracy'))\n",
    "\n",
    "            accuracyScores.append(accuraccy)\n",
    "    \n",
    "        bestIndex = np.argmax(accuracyScores)\n",
    "        \n",
    "        #Update current best selection\n",
    "        selection.append(candFeatures[bestIndex])\n",
    "        del candFeatures[bestIndex]\n",
    "        \n",
    "    \n",
    "    \n",
    "    train_X_S = train_X[:, selection]\n",
    "    #print(train_X_S.shape)\n",
    "    test_X_S = test_X[:, selection]\n",
    "    #print(test_X_S.shape)\n",
    "\n",
    "\n",
    "    svmClassifier = sklearn.svm.LinearSVC()\n",
    "    svmClassifier.fit(train_X_S, train_y)\n",
    "    \n",
    "    train_y_hat = svmClassifier.predict(train_X_S)\n",
    "    test_y_hat = svmClassifier.predict(test_X_S)\n",
    "    \n",
    "    \n",
    "    returnList[\"trainAcc\"] = sklearn.metrics.accuracy_score(train_y, train_y_hat)\n",
    "    returnList[\"trainConfM\"] = sklearn.metrics.confusion_matrix(train_y, train_y_hat)\n",
    "    returnList[\"testAcc\"] = sklearn.metrics.accuracy_score(test_y, test_y_hat)\n",
    "    returnList[\"testConfM\"] = sklearn.metrics.confusion_matrix(test_y, test_y_hat)\n",
    "    returnList[\"featuresSelectedNumeric\"] = [selection]\n",
    "    returnList[\"featuresSelectedText\"] = [originalData['feature_names'][i] for i in selection]    \n",
    "    \n",
    "    return returnList\n",
    "    \n",
    "\n",
    "\n",
    "#print(forward_selector(13, y_train, y_test, x_train, x_test, 1, 10, dataRaw))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test code\n",
    "\n",
    "\"\"\"\n",
    "svmClassifier = sklearn.svm.LinearSVC()\n",
    "svmClassifier.fit(x_train[:,[6, 0, 12, 10]], y_train)\n",
    "    \n",
    "train_y_hat = svmClassifier.predict(x_train[:,[6, 0, 12, 10]])\n",
    "test_y_hat = svmClassifier.predict(x_test[:,[6, 0, 12, 10]])\n",
    "\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(y_train, train_y_hat))\n",
    "print(sklearn.metrics.confusion_matrix(y_train, train_y_hat))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data presented in the table 4.1\n",
    "\n",
    "accResults = []\n",
    "\n",
    "for ii in (range (1,14,1)):\n",
    "    \n",
    "    result = forward_selector(ii, y_train, y_test, x_train, x_test, 1, 10, dataRaw)\n",
    "    accResults.append(result[\"trainAcc\"])\n",
    "    print(\"For cardinality\", ii, \"Best features are: \", result[\"featuresSelectedNumeric\"])\n",
    "    print(\"For cardinality\", ii, \"Best features are: \", result[\"featuresSelectedText\"])\n",
    "    print(\"Giving performance in train set of \", result[\"trainAcc\"])\n",
    "    print(\"Giving performance in test set of \", result[\"testAcc\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "## Finding best stes for different stopping rules\n",
    "\n",
    "best_untill_decline_cardinality = None\n",
    "for i in range(len(accResults)):\n",
    "    if i == len(accResults)-1:\n",
    "        break\n",
    "    elif accResults[i] < accResults[i+1]:\n",
    "        next\n",
    "    elif accResults[i] >= accResults[i+1]:\n",
    "        best_untill_decline = i+1\n",
    "        break\n",
    "        \n",
    "        \n",
    "    \n",
    "print(\"Best set up to a point where model performance on train data starts to decrease is at cardinality: \", \n",
    "      best_untill_decline)\n",
    "\n",
    "\n",
    "print(\"Best overall set is: \", (np.argmax(accResults)+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining backward selection algorithm \n",
    "\n",
    "def backward_selector(maxFeatureN, train_y, test_y, train_X, test_X, random_seed, cv_k, originalData):\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    returnList = {\"maxFeatureN\": maxFeatureN}\n",
    "    \n",
    "    candFeatures = list(range(train_X.shape[1]))\n",
    "    selection = []\n",
    "    \n",
    "    for i in range(train_X.shape[1] - maxFeatureN):\n",
    "        accuracyScores = []\n",
    "        \n",
    "        for a, c in enumerate(candFeatures): \n",
    "            S = list(candFeatures)\n",
    "            del S[a]\n",
    "\n",
    "            train_X_S = train_X[:,S]\n",
    "\n",
    "            # fitting SVM classifier\n",
    "            svm_classifier = sklearn.svm.LinearSVC()\n",
    "\n",
    "            accuraccy = np.mean(model_selection.cross_val_score(svm_classifier, \n",
    "                                                                train_X_S, \n",
    "                                                                train_y, \n",
    "                                                                cv=cv_k, \n",
    "                                                                scoring='accuracy'))\n",
    "\n",
    "            accuracyScores.append(accuraccy)\n",
    "    \n",
    "        bestIndex = np.argmax(accuracyScores)\n",
    "        del candFeatures[bestIndex]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_X_S = train_X[:, candFeatures]\n",
    "    #print(train_X_S.shape)\n",
    "    test_X_S = test_X[:, candFeatures]\n",
    "    #print(test_X_S.shape)\n",
    "\n",
    "\n",
    "    svmClassifier = sklearn.svm.LinearSVC()\n",
    "    svmClassifier.fit(train_X_S, train_y)\n",
    "    \n",
    "    train_y_hat = svmClassifier.predict(train_X_S)\n",
    "    test_y_hat = svmClassifier.predict(test_X_S)\n",
    "    \n",
    "    \n",
    "    returnList[\"trainAcc\"] = sklearn.metrics.accuracy_score(train_y, train_y_hat)\n",
    "    returnList[\"trainConfM\"] = sklearn.metrics.confusion_matrix(train_y, train_y_hat)\n",
    "    returnList[\"testAcc\"] = sklearn.metrics.accuracy_score(test_y, test_y_hat)\n",
    "    returnList[\"testConfM\"] = sklearn.metrics.confusion_matrix(test_y, test_y_hat)\n",
    "    returnList[\"featuresSelectedNumeric\"] = [candFeatures]\n",
    "    returnList[\"featuresSelectedText\"] = [originalData['feature_names'][i] for i in candFeatures]\n",
    "    \n",
    "    \n",
    "    return returnList\n",
    "    \n",
    "\n",
    "\n",
    "#print(backward_selector(11, y_train, y_test, x_train, x_test, 1, 10, dataRaw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 1)\n",
      "(54, 1)\n",
      "For cardinality 1 Best features are:  [[6]]\n",
      "For cardinality 1 Best features are:  ['flavanoids']\n",
      "Giving performance in train set of  0.7661290322580645\n",
      "Giving performance in test set of  0.8703703703703703\n",
      "\n",
      "\n",
      "(124, 2)\n",
      "(54, 2)\n",
      "For cardinality 2 Best features are:  [[6, 12]]\n",
      "For cardinality 2 Best features are:  ['flavanoids', 'proline']\n",
      "Giving performance in train set of  0.9112903225806451\n",
      "Giving performance in test set of  0.8703703703703703\n",
      "\n",
      "\n",
      "(124, 3)\n",
      "(54, 3)\n",
      "For cardinality 3 Best features are:  [[6, 10, 12]]\n",
      "For cardinality 3 Best features are:  ['flavanoids', 'hue', 'proline']\n",
      "Giving performance in train set of  0.967741935483871\n",
      "Giving performance in test set of  0.9074074074074074\n",
      "\n",
      "\n",
      "(124, 4)\n",
      "(54, 4)\n",
      "For cardinality 4 Best features are:  [[0, 6, 10, 12]]\n",
      "For cardinality 4 Best features are:  ['alcohol', 'flavanoids', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9758064516129032\n",
      "Giving performance in test set of  0.9629629629629629\n",
      "\n",
      "\n",
      "(124, 5)\n",
      "(54, 5)\n",
      "For cardinality 5 Best features are:  [[0, 6, 9, 10, 12]]\n",
      "For cardinality 5 Best features are:  ['alcohol', 'flavanoids', 'color_intensity', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  0.9814814814814815\n",
      "\n",
      "\n",
      "(124, 6)\n",
      "(54, 6)\n",
      "For cardinality 6 Best features are:  [[0, 2, 6, 9, 10, 12]]\n",
      "For cardinality 6 Best features are:  ['alcohol', 'ash', 'flavanoids', 'color_intensity', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 7)\n",
      "(54, 7)\n",
      "For cardinality 7 Best features are:  [[0, 2, 6, 8, 9, 10, 12]]\n",
      "For cardinality 7 Best features are:  ['alcohol', 'ash', 'flavanoids', 'proanthocyanins', 'color_intensity', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9838709677419355\n",
      "Giving performance in test set of  0.9814814814814815\n",
      "\n",
      "\n",
      "(124, 8)\n",
      "(54, 8)\n",
      "For cardinality 8 Best features are:  [[0, 2, 3, 6, 8, 9, 10, 12]]\n",
      "For cardinality 8 Best features are:  ['alcohol', 'ash', 'alcalinity_of_ash', 'flavanoids', 'proanthocyanins', 'color_intensity', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 9)\n",
      "(54, 9)\n",
      "For cardinality 9 Best features are:  [[0, 2, 3, 6, 7, 8, 9, 10, 12]]\n",
      "For cardinality 9 Best features are:  ['alcohol', 'ash', 'alcalinity_of_ash', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 10)\n",
      "(54, 10)\n",
      "For cardinality 10 Best features are:  [[0, 2, 3, 6, 7, 8, 9, 10, 11, 12]]\n",
      "For cardinality 10 Best features are:  ['alcohol', 'ash', 'alcalinity_of_ash', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 11)\n",
      "(54, 11)\n",
      "For cardinality 11 Best features are:  [[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12]]\n",
      "For cardinality 11 Best features are:  ['alcohol', 'ash', 'alcalinity_of_ash', 'magnesium', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 12)\n",
      "(54, 12)\n",
      "For cardinality 12 Best features are:  [[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]\n",
      "For cardinality 12 Best features are:  ['alcohol', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "(124, 13)\n",
      "(54, 13)\n",
      "For cardinality 13 Best features are:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]\n",
      "For cardinality 13 Best features are:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Giving performance in train set of  0.9919354838709677\n",
      "Giving performance in test set of  1.0\n",
      "\n",
      "\n",
      "[0.7661290322580645, 0.9112903225806451, 0.967741935483871, 0.9758064516129032, 0.9919354838709677, 0.9919354838709677, 0.9838709677419355, 0.9919354838709677, 0.9919354838709677, 0.9919354838709677, 0.9919354838709677, 0.9919354838709677, 0.9919354838709677]\n",
      "Best set up to a point where model performance on train data starts to decrease is at cardinality:  8\n",
      "Best overall set is:  5\n"
     ]
    }
   ],
   "source": [
    "## For data presented in the table 4.2\n",
    "\n",
    "accResults = []\n",
    "\n",
    "for ii in (range (1,14,1)):\n",
    "    \n",
    "    result = backward_selector(ii, y_train, y_test, x_train, x_test, 1, 10, dataRaw)\n",
    "    accResults.append(result[\"trainAcc\"])\n",
    "    print(\"For cardinality\", ii, \"Best features are: \", result[\"featuresSelectedNumeric\"])\n",
    "    print(\"For cardinality\", ii, \"Best features are: \", result[\"featuresSelectedText\"])\n",
    "    print(\"Giving performance in train set of \", result[\"trainAcc\"])\n",
    "    print(\"Giving performance in test set of \", result[\"testAcc\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "## Finding best stes for different stopping rules\n",
    "\n",
    "best_untill_decline_cardinality = None\n",
    "for i in range(-1,-13,-1):\n",
    "    \n",
    "    if accResults[i] <= accResults[i-1]:\n",
    "        next\n",
    "    elif accResults[i] > accResults[i-1]:\n",
    "        best_untill_decline = 14 + i\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(accResults)\n",
    "    \n",
    "print(\"Best set up to a point where model performance on train data starts to decrease is at cardinality: \", \n",
    "      best_untill_decline)\n",
    "\n",
    "\n",
    "print(\"Best overall set is: \", (np.argmax(accResults)+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test code\n",
    "\n",
    "\"\"\"\n",
    "svmClassifier = sklearn.svm.LinearSVC()\n",
    "svmClassifier.fit(x_train[:,[0, 2, 3, 6, 8, 9, 10, 12]], y_train)\n",
    "    \n",
    "train_y_hat = svmClassifier.predict(x_train[:,[0, 2, 3, 6, 8, 9, 10, 12]])\n",
    "test_y_hat = svmClassifier.predict(x_test[:,[0, 2, 3, 6, 8, 9, 10, 12]])\n",
    "\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(y_train, train_y_hat))\n",
    "print(sklearn.metrics.confusion_matrix(y_train, train_y_hat))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
