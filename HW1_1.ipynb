{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Subtask 1:  Data Preparation\n",
    "\n",
    "np.random.seed(122)\n",
    "\n",
    "# Loading data\n",
    "dataRaw = sklearn.datasets.fetch_california_housing()\n",
    "\n",
    "X = dataRaw['data']\n",
    "Y = dataRaw['target']\n",
    "\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "# Getting feature names of the data\n",
    "featureNames = dataRaw['feature_names']\n",
    "print('Independent features are: ', featureNames)\n",
    "\n",
    "targetNames = dataRaw['target_names']\n",
    "print('Target feature of dataset: ', targetNames)\n",
    "\n",
    "# Shuffling array \n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "\n",
    "# Splitting data to training and test set\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "\n",
    "# Test and \n",
    "print('Samples in training data: ', x_train.shape[0])\n",
    "print('Samples in test data: ', x_test.shape[0])\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 2:  Regression Using scikit-learn\n",
    "\n",
    "lrSKL = linear_model.LinearRegression(fit_intercept = False)\n",
    "lrSKL.fit(x_train, y_train)\n",
    "\n",
    "y_hat_trainSKL = lrSKL.predict(x_train)\n",
    "y_hat_testSKL = lrSKL.predict(x_test)\n",
    "\n",
    "\n",
    "testMSE_SKL = metrics.mean_squared_error(y_test, y_hat_testSKL, squared=True)\n",
    "trainMSE_SKL = metrics.mean_squared_error(y_train, y_hat_trainSKL, squared=True)\n",
    "\n",
    "print('scikit-learn\\'s regression mean squared error on training data: ', trainMSE_SKL)\n",
    "print('scikit-learn\\'s regression mean squared error on test data: ', testMSE_SKL)\n",
    "\n",
    "#print(lrSKL.coef_)\n",
    "#print(lrSKL.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 3:  Implement Linear Regression on Your Own I\n",
    "\n",
    "CovarianceMatrix = np.dot(x_train.T, x_train)\n",
    "closedFormW = np.dot(np.linalg.inv(CovarianceMatrix), np.dot(x_train.T, y_train))\n",
    "\n",
    "print('Weight vector of clsoed form solution: ', closedFormW)\n",
    "\n",
    "y_hat_trainClosedForm  = np.sum(np.multiply(closedFormW.T, x_train),axis=1)\n",
    "y_hat_testClosedForm = np.sum(np.multiply(closedFormW.T, x_test),axis=1)\n",
    "\n",
    "testMSE_closedForm = np.mean((y_test - y_hat_testClosedForm)**2)\n",
    "trainMSE_closedForm = np.mean((y_train - y_hat_trainClosedForm)**2)\n",
    "\n",
    "print('closed-form\\'s regression mean squared error on train data: ', trainMSE_closedForm)\n",
    "print('closed-form\\'s regression mean squared error on test data: ', testMSE_closedForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 4:  Implement Least Squares Linear Regression on Your Own II\n",
    "## Abandoned try\n",
    "\n",
    "\"\"\"\n",
    "def GD(X, Y, X_test, Y_test, numIterations = 1000):\n",
    "    \n",
    "    ## Initialize variables \n",
    "    losses = []\n",
    "    MSEs = []\n",
    "    MSEs_test = []\n",
    "    Ws = []\n",
    "    w = np.zeros(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    ## MSE before first iteration\n",
    "    k = [0]\n",
    "    MSEs.append(np.mean((Y - np.dot(X, w))**2))\n",
    "    MSEs_test.append(np.mean((Y_test - np.dot(X_test, w))**2))\n",
    "    Ws.append(w)\n",
    "    \n",
    "    for t in range(numIterations):\n",
    "        \n",
    "        lr = (10e-6) / (1 + t + 1) ## because iterator starts from zero\n",
    "        print(lr)\n",
    "                       \n",
    "        y_hat = np.dot(X, w)\n",
    "        loss =  Y - y_hat\n",
    "        mse = np.mean((Y - y_hat)**2)  \n",
    "        \n",
    "        ## Update gradient; based on slides\n",
    "        gradient = np.dot(X.T, loss) * (-2/n)        \n",
    "        \n",
    "        ## Update weight vector\n",
    "        w = w - lr*gradient    \n",
    "        \n",
    "        \n",
    "        if(t % 1000 == 0):\n",
    "            losses.append(loss)\n",
    "            MSEs.append(mse)\n",
    "            MSEs_test.append(np.mean((Y_test - np.dot(X_test, w))**2))\n",
    "            Ws.append(w)\n",
    "            k.append(k[-1] + 1)\n",
    "\n",
    "        \n",
    "    return losses, MSEs, MSEs_test, Ws, k\n",
    "    \n",
    "    \n",
    "trainLosses, trainMSEs, testMSEs, trainWs, k = GD(x_train, y_train, x_test, y_test, numIterations = 100000)  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(k, trainMSEs, '*', c = 'b', label = 'MSE by iteration')\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('$MSE$')\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0,6))\n",
    "plt.legend()\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 4:  Implement Least Squares Linear Regression on Your Own II\n",
    "\n",
    "def GD1(X, Y, X_test, Y_test, numIterations = 1000):\n",
    "    \n",
    "    ## Initialize variables \n",
    "    losses = []\n",
    "    MSEs = []\n",
    "    MSEs_test = []\n",
    "    \n",
    "    Ws = []\n",
    "    w = np.zeros(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    ## Before initial gradient descent step\n",
    "    k = [0]\n",
    "    MSEs.append(np.mean((Y - np.dot(X, w))**2))\n",
    "    Ws.append(w)\n",
    "    MSEs_test.append(np.mean((Y_test - np.dot(X_test, w))**2))\n",
    "    TwoLastMSEs = []\n",
    "    TwoLastMSEs.append(np.mean((Y - np.dot(X, w))**2))\n",
    "    \n",
    "    ## Updating_gradient\n",
    "    for t in range(1, (numIterations+1)):\n",
    "        \n",
    "        ## Updating learning rate\n",
    "        lr = (10e-6) / (1 + t)\n",
    "\n",
    "        \n",
    "        ## Upgrading weight vector\n",
    "        y_hat = np.dot(X, w)\n",
    "        loss =  Y - y_hat\n",
    "        gradient = np.dot(X.T, loss) * (-2/n)        \n",
    "        w = w - lr*gradient\n",
    "        \n",
    "        # Calculating errors\n",
    "        mse = np.mean((Y - y_hat)**2)\n",
    "        mse_test = np.mean((Y_test - np.dot(X_test, w))**2)        \n",
    "        \n",
    "        if(t % 1000 == 0):\n",
    "            losses.append(loss)\n",
    "            MSEs.append(mse)\n",
    "            MSEs_test.append(mse_test)\n",
    "            #print(Y_test.shape)\n",
    "            Ws.append(w)\n",
    "            k.append(k[-1] + 1)\n",
    "\n",
    "    return losses, MSEs, MSEs_test, Ws, k\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "trainLosses, trainMSEs, testMSEs, trainWs, k = GD1(x_train, y_train, x_test, y_test, numIterations = 100000)  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(k, trainMSEs, '*', c = 'b', label = 'MSE by iteration at k * 1000 - training sample')\n",
    "plt.plot(k, testMSEs, '.', c = 'r', label = 'MSE by iteration at k * 1000 - test sample')\n",
    "\n",
    "\n",
    "plt.xlabel('k * 1000 $th$ iteration')\n",
    "plt.ylabel('$MSE$')\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0,6))\n",
    "plt.title('Default learning rate update scheduler')\n",
    "plt.legend()\n",
    "\n",
    "print('Default gradient descent\\'s regression mean squared error on train data: ', trainMSEs[-1])\n",
    "print('Default gradient descent\\'s regression mean squared error on test data: ', testMSEs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 5:  Implement Least Squares Linear Regression on Your Own III\n",
    "def GD2(X, Y, X_test, Y_test, numIterations = 1000):\n",
    "    \n",
    "    ## Initialize variables \n",
    "    losses = []\n",
    "    MSEs = []\n",
    "    MSEs_test = []\n",
    "    \n",
    "    Ws = []\n",
    "    w = np.zeros(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    ## Before initial gradient descent step\n",
    "    k = [0]\n",
    "    MSEs.append(np.mean((Y - np.dot(X, w))**2))\n",
    "    Ws.append(w)\n",
    "    MSEs_test.append(np.mean((Y_test - np.dot(X_test, w))**2))\n",
    "    lr = (10e-8)\n",
    "    TwoLastMSEs = []\n",
    "    TwoLastMSEs.append(np.mean((Y - np.dot(X, w))**2))\n",
    "    \n",
    "    ## Updating_gradient\n",
    "    for t in range(1, (numIterations+1)):\n",
    "        \n",
    "        ## Updating learning rate\n",
    "\n",
    "        if (t != 1):\n",
    "            if(TwoLastMSEs[1] < TwoLastMSEs[0]):\n",
    "                lr = lr * 1.1\n",
    "\n",
    "            elif(TwoLastMSEs[1] >= TwoLastMSEs[0]):\n",
    "                    lr = lr / 2\n",
    "\n",
    "                       \n",
    "        ## Upgrading weight vector\n",
    "        y_hat = np.dot(X, w)\n",
    "        loss =  Y - y_hat\n",
    "        gradient = np.dot(X.T, loss) * (-2/n)        \n",
    "        w = w - lr*gradient\n",
    "        \n",
    "        # Calculating errors\n",
    "        mse = np.mean((Y - y_hat)**2)\n",
    "        mse_test = np.mean((Y_test - np.dot(X_test, w))**2)                  \n",
    "        \n",
    "        if(t == 1):\n",
    "            TwoLastMSEs.append(mse)\n",
    "        if (t != 1):\n",
    "            TwoLastMSEs.pop(0)\n",
    "            TwoLastMSEs.append(mse)\n",
    "        \n",
    "        \n",
    "        if(t % 1000 == 0):\n",
    "            losses.append(loss)\n",
    "            MSEs.append(mse)\n",
    "            MSEs_test.append(mse_test)\n",
    "            Ws.append(w)\n",
    "            k.append(k[-1] + 1)\n",
    "\n",
    "    return losses, MSEs, MSEs_test, Ws, k\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "trainLosses, trainMSEs, testMSEs, trainWs, k = GD2(x_train, y_train, x_test, y_test, numIterations = 100000)  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(k, trainMSEs, '*', c = 'b', label = 'MSE by iteration at k * 1000 - training sample')\n",
    "plt.plot(k, testMSEs, '.', c = 'r', label = 'MSE by iteration at k * 1000 - test sample')\n",
    "\n",
    "\n",
    "plt.xlabel('k * 1000 $th$ iteration')\n",
    "plt.ylabel('$MSE$')\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0,6))\n",
    "plt.title('Bold driver learning rate update scheduler')\n",
    "plt.legend()\n",
    "\n",
    "print('Bold driver like gradient descent\\'s regression mean squared error on train data: ', trainMSEs[-1])\n",
    "print('Bold driver like  gradient descent\\'s regression mean squared error on test data: ', testMSEs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtask 6:  Implement Least Squares Linear Regression on Your Own IV\n",
    "\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "\n",
    "x_train_scaled = scalerX.transform(x_train)\n",
    "x_test_scaled = scalerX.transform(x_test)\n",
    "\n",
    "trainLosses, trainMSEs, testMSEs, trainWs, k = GD1(x_train_scaled, y_train, x_test_scaled, y_test, numIterations = 100000)  \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(k, trainMSEs, '*', c = 'b', label = 'MSE by iteration at k * 1000 - training sample')\n",
    "plt.plot(k, testMSEs, '.', c = 'r', label = 'MSE by iteration at k * 1000 - test sample')\n",
    "\n",
    "\n",
    "plt.xlabel('k * 1000 $th$ iteration')\n",
    "plt.ylabel('$MSE$')\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0,6))\n",
    "plt.title('Default learning rate update scheduler with MinMax scaled features')\n",
    "plt.legend()\n",
    "\n",
    "print('Default gradient descent\\'s regression with MinMax scaled features mean squared error on train data: ', \n",
    "      trainMSEs[-1])\n",
    "print('Default gradient descent\\'s regression with MinMax scaled features mean squared error on test data: ', \n",
    "      testMSEs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bold driver like gradient descent's regression with MinMax scaled features mean squared error on train data:  0.5906940563256636\n",
      "Bold driver like  gradient descent's regression with MinMax scaled features mean squared error on test data:  0.6464243058987427\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Subtask 6:  Implement Least Squares Linear Regression on Your Own IV\n",
    "\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "\n",
    "x_train_scaled = scalerX.transform(x_train)\n",
    "x_test_scaled = scalerX.transform(x_test)\n",
    "\n",
    "trainLosses, trainMSEs, testMSEs, trainWs, k = GD2(x_train_scaled, y_train, x_test_scaled, y_test, numIterations = 100000)  \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(k, trainMSEs, '*', c = 'b', label = 'MSE by iteration at k * 1000 - training sample')\n",
    "plt.plot(k, testMSEs, '.', c = 'r', label = 'MSE by iteration at k * 1000 - test sample')\n",
    "\n",
    "\n",
    "plt.xlabel('k * 1000 $th$ iteration')\n",
    "plt.ylabel('$MSE$')\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0,6))\n",
    "plt.title('Bold driver learning rate update scheduler with MinMax scaled features')\n",
    "plt.legend()\n",
    "\n",
    "print('Bold driver like gradient descent\\'s regression with MinMax scaled features mean squared error on train data: ', \n",
    "      trainMSEs[-1])\n",
    "print('Bold driver like  gradient descent\\'s regression with MinMax scaled features mean squared error on test data: ', \n",
    "      testMSEs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14448, 8)\n",
      "(6192, 8)\n",
      "At polynomial level  1 MSE on training data:  0.5906940287969901\n",
      "At polynomial level  1 MSE on test data:  0.6464752155710056\n",
      "(14448, 44)\n",
      "(6192, 44)\n",
      "At polynomial level  2 MSE on training data:  0.4112100632957337\n",
      "At polynomial level  2 MSE on test data:  189.4389278074302\n",
      "(14448, 164)\n",
      "(6192, 164)\n",
      "At polynomial level  3 MSE on training data:  0.3367652855181704\n",
      "At polynomial level  3 MSE on test data:  13548004.708376527\n",
      "(14448, 494)\n",
      "(6192, 494)\n",
      "At polynomial level  4 MSE on training data:  0.2762800964498828\n",
      "At polynomial level  4 MSE on test data:  10117936906002.094\n"
     ]
    }
   ],
   "source": [
    "# Subtask  7:  Least  Squares  Linear  Regression  Using  Higher-order  Features\n",
    "\n",
    "# Scaling data\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "\n",
    "x_train_scaled = scalerX.transform(x_train)\n",
    "x_test_scaled = scalerX.transform(x_test)\n",
    "\n",
    "#x_train_scaled = (x_train)\n",
    "#x_test_scaled = (x_test)\n",
    "\n",
    "\n",
    "# Poly\n",
    "for i in [1, 2,3,4]:\n",
    "    poly = preprocessing.PolynomialFeatures(degree = i, include_bias= False)\n",
    "    poly.fit(x_train_scaled)\n",
    "    \n",
    "    x_train_scaled_poly = poly.transform(x_train_scaled)\n",
    "    x_test_scaled_poly = poly.transform(x_test_scaled)\n",
    "    \n",
    "    \n",
    "    #print(x_train_scaled_poly.shape)\n",
    "    #print(x_test_scaled_poly.shape)\n",
    "\n",
    "    model_reg = linear_model.LinearRegression(fit_intercept = False)\n",
    "    model_reg.fit(x_train_scaled_poly, y_train)\n",
    "\n",
    "    y_hat_trainPoly = model_reg.predict(x_train_scaled_poly)\n",
    "    y_hat_testPoly = model_reg.predict(x_test_scaled_poly)\n",
    "    \n",
    "    test_poly = metrics.mean_squared_error(y_test, y_hat_testPoly, squared=True)\n",
    "    train_poly = metrics.mean_squared_error(y_train, y_hat_trainPoly, squared=True)\n",
    "\n",
    "    print('At polynomial level ',i, 'MSE on training data: ', train_poly)\n",
    "    print('At polynomial level ',i, 'MSE on test data: ', test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
